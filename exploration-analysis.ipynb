{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" \n",
    "     src=\"https://images.squarespace-cdn.com/content/5f05b198fd381f3436f95004/1594554017779-B4XMFH0WGYLLPFEN8IYO/unifai-logo-black.png?format=1500w&content-type=image%2Fpng\" \n",
    "     alt=\"Unifai Logo\" \n",
    "     width=\"20%\" style=\"padding: 10px; \">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Champagne Coding - February 23, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a ‚Äúnotebook‚Äù?\n",
    "\n",
    "Notebooks are an important part of the data analysis / data science workflow. \n",
    "\n",
    "It allows you to integrate all of the following in one place:\n",
    "* Code\n",
    "* Display the output\n",
    "* Add visualizations\n",
    "* Add narrative text\n",
    "* Add mathematical equations\n",
    "* ... and more :) \n",
    "\n",
    "All with the purpose of making work transparent, understandable, and shareable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started!\n",
    "\n",
    "We'll start by importing some modules we know we will use, like pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data set\n",
    "\n",
    "We are going to read in this file on heatpump data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('LabData1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any analysis or manipulations to the data, we need to know what we're looking at. Let's start with some simple exploratory analysis so we can get a good feel for our data's main characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ```.keys()``` to find out what headers we have in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not uncommon for column headers (also called tags or sensor IDs in industry) to be a little bit cryptic. It's a good idea to check if you have any additional knowledge of what these names mean so you can do more in depth interpretation.\n",
    "\n",
    "The interpretation is available in the file called sensor_metadata.xlsx.\n",
    "\n",
    "#### üí° Exercise: Read in the sensor metadata file.\n",
    "üëáüèº Test in the cell below. If you can't figure it out, take a peek at [pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensor_metadata = pd.read_excel('sensor_metadata.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's see how the data actually looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ```.head()``` to view the first few rows of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ```.shape```, we can check the dimensionality of the dataframe as a tuple: ```(number of rows, number of columns)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much time is that??\n",
    "\n",
    "#### üí° Exercise: Find when the data starts and ends.\n",
    "üëáüèº Test in the cell below. Hint [here](https://www.kite.com/python/answers/how-to-find-the-max-value-of-a-pandas-dataframe-column-in-python).\n",
    "\n",
    "Start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ```.describe()```, we can generate descriptive statistics of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data types\n",
    "There are many types of data, and having inconsistent or unexpected data types can pose some problems later. \n",
    "\n",
    "For example, if you have a column that is time, but it is stored as \"strings\", it could get confusing when you try to apply date specific manipulations. Similarly, if you are storing record ids (i.e. 1, 2, 3, 4), it's a little annoying if they're stored as floats (1.0, 2.0, 3.0...)\n",
    "\n",
    "Here is an overview of the data types that Python supports and how they can be used.\n",
    "\n",
    "<img align=\"center\" \n",
    "     src=\"https://miro.medium.com/max/3280/1*PRXWM7hwR9HHbpe-goewFQ.png\" \n",
    "     alt=\"Pandas datatypes\" \n",
    "     width=\"80%\" style=\"padding: 10px; \">\n",
    "     \n",
    "\n",
    "So let's check if the data types make sense for our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and change the timestamp column datatype to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = pd.to_datetime(data['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this affect the datatypes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for empty rows.\n",
    "It's not uncommon in industrial data sets for some data to be missing. There are lot's of reasons for this - lack of connectivity, broken sensor, different sampling rate. You can check if any data is missing in any of the columns like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that there aren't any empty rows, which is great! \n",
    "\n",
    "But if you did have empty rows, there are some things to consider:\n",
    "* Does data need to be consistent for my analysis? \n",
    "* If you're doing manipulations to the data (i.e. Column_A + Column_B), how does missing data affect the resulting output? \n",
    "\n",
    "Depending on this, you have some options:\n",
    "* Should I **_delete_** rows where all columns (or a subset of the columns) are missing data?\n",
    "* Should I **_fill_** the empty rows? What do you fill them with? The mean? The median? 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries Index\n",
    "We're working with **timeseries** data. Timeseries data is a sequence of data indexed in time. It is collected at different points in time, and typically consists of measurements collected from the same source over a time interval.The time element is important, since we are using it to track changes over time. \n",
    "\n",
    "To make working with timeseries data easier, we will update our index. \n",
    "\n",
    "If you peek above (and below here), you'll see that the current index is a range index of numbers (0, 1, 2...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace that index with our ```timestamp``` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('timestamp', \n",
    "               drop=True, \n",
    "               inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "Now that we know a little bit about our data, let's use visualization to explore further.\n",
    "\n",
    "We'll use ```plotly express```, which is an easy-to-use, high-level interface to Plotly, which operates on a variety of types of data and produces easy-to-style figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at the Indoor Unit Current, ```A_I_Avg```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(data, \n",
    "              x = data.index, \n",
    "              y=\"A_I_Avg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üí° Exercise: Plot some of the other sensors.\n",
    "üëáüèº Test in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üí° Exercise: Plot a scatter visualization with two of the sensors.\n",
    "üëáüèº Test in the cell below. Hint [here](https://plotly.com/python/line-and-scatter/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Detect fan speed using ```A_I_Avg```\n",
    "\n",
    "The fan has 5 operating modes: \n",
    "* Off\n",
    "* Quiet\n",
    "* Low\n",
    "* Medium\n",
    "* High\n",
    "\n",
    "There is no sensor that directly captures this, but we can estimate using the indoor unit current values as a proxy. We'll create a list of bins to capture the following: \n",
    "* Off < 0.07\n",
    "* 0.07 <= Quiet < 0.1\n",
    "* 0.1 <= Low < 0.13\n",
    "* 0.13 <= Medium < 0.2\n",
    "* 0.2 <= High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "\n",
    "edges = [-inf, 0.07, 0.1, 0.13, 0.2, +inf]\n",
    "labels = [\"Off\", \"Quiet\", \"Low\", \"Medium\", \"High\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FanSpeed']= pd.cut(data.A_I_Avg, \n",
    "                         bins=edges, \n",
    "                         labels=labels)\n",
    "\n",
    "data.FanSpeed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use visualization to see how that came out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, \n",
    "                 x = data.index, \n",
    "                 y=\"A_I_Avg\", \n",
    "                 color = \"FanSpeed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's about right!\n",
    "\n",
    "Now, let's use a scatter matrix and color the pairwise plots by fanspeed to get a feel for how the rest of the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(data,\n",
    "                        dimensions=[\"A_I_Avg\", \"T_AI\", \"P_Total_Avg\"],\n",
    "                        color=\"FanSpeed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate the volumetric flow rate.\n",
    "\n",
    "The volumetric flow rate is a function of the fan speed and the current. Based on tests in the labs, we know that the equations are the following:\n",
    "* High: 2056x+55.831\n",
    "* Medium: 4096.9x-137.66\n",
    "* Low: 6879x-334.11\n",
    "* Quiet: 8510.6x-355.47\n",
    "\n",
    "Knowing that, we started putting together the function to calculate the volumetric flow rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_vfr(row):\n",
    "    \"\"\"\n",
    "    Calculated Volumetric Flow Rate\n",
    "    \"\"\"\n",
    "    if row['FanSpeed'] == 'High':\n",
    "        vfr = (2056 * row['A_I_Avg']) + 55.831\n",
    "        \n",
    "    elif row['FanSpeed'] == 'Medium':\n",
    "        vfr = (4096.9 * row['A_I_Avg']) - 137.66\n",
    "\n",
    "    else:\n",
    "        vfr = np.nan\n",
    "        \n",
    "    return convert_vfr_to_m3s(vfr)\n",
    "\n",
    "\n",
    "def convert_vfr_to_m3s(vfr):\n",
    "    \n",
    "    return vfr*(1/60)*(1/35.3147)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üí° Exercise: Update the function with the missing VFR calculations for Low and Quiet.\n",
    "üëÜüèº Do this in the cell above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a column for volumetric flow rate and apply the functions we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vfr_m3s'] = data.apply(calculate_vfr, axis = 1)\n",
    "\n",
    "data['vfr_m3s'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it looks using visualization.\n",
    "\n",
    "‚ö†Ô∏è You will __only__ see the scatter plot for high and medium if you didn't update the calculate vfr function above!!!! If your VFR function was updated correctly, and you run the calculation again, you should see a scatter plot that includes Low and Quiet Fan speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, \n",
    "                 x = data.index, \n",
    "                 y=\"vfr_m3s\", \n",
    "                 color = \"FanSpeed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate Heat Output\n",
    "\n",
    "We're depending on a couple of constants cp (kJ/kgC) and rho (kg/m3), which we included in the cell here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_cp = 1.005\n",
    "constant_rho = 1.2\n",
    "\n",
    "from statistics import mean \n",
    "def calculate_heat_output(row):\n",
    "    \"\"\"\n",
    "    T_AI: Indoor return temp\n",
    "    T_A01: Indoor supply temp (1)\n",
    "    T_A02: Indoor supply temp (2)\n",
    "    \"\"\"\n",
    "    vfr_m3s = calculate_vfr(row)\n",
    "    \n",
    "    supply_minus_return_temp = ((mean([row['T_AO1'], row['T_AO2']]) - row['T_AI']))\n",
    "    \n",
    "    heat_output_watts = 1000 * vfr_m3s * constant_cp * constant_rho * supply_minus_return_temp\n",
    "    \n",
    "    return heat_output_watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['heat_output'] = data.apply(calculate_heat_output, axis = 1)\n",
    "\n",
    "data['heat_output'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's see how it looks using visualization.\n",
    "\n",
    "‚ö†Ô∏è You will __only__ see the scatter plot for high and medium if you didn't update the calculate vfr function above!!!! If your VFR function was updated correctly, and you run the calculation again, you should see a scatter plot that includes Low and Quiet Fan speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, \n",
    "                 x = data.index, \n",
    "                 y=\"heat_output\", \n",
    "                 color = \"FanSpeed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the significance of the heat output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the Coefficient of Performance\n",
    "Calculate the coefficient of performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cop(row):\n",
    "    \n",
    "    heat_output = calculate_heat_output(row)\n",
    "    \n",
    "    try:\n",
    "        cop = heat_output/row['P_Total_Avg']\n",
    "        return cop\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cop'] = data.apply(calculate_cop, axis = 1)\n",
    "\n",
    "data['cop'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's see how it looks using visualization.\n",
    "\n",
    "‚ö†Ô∏è You will __only__ see the scatter plot for high and medium if you didn't update the calculate vfr function above!!!! If your VFR function was updated correctly, and you run the calculation again, you should see a scatter plot that includes Low and Quiet Fan speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, \n",
    "                 x = data.index, \n",
    "                 y=\"cop\", \n",
    "                 color = \"FanSpeed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think there are outliers in the data? How would you filter them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üí° Exercise: Identify when the fan is ramping or in steady state.\n",
    "\n",
    "Hint - you can try using ```pandas diff``` [functionality](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html) on A_I_Avg to see if any obvious patterns emerge.\n",
    "\n",
    "Plot the difference as well as the A_I_Avg sensor to see what we mean :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = data.index, \n",
    "                         y=data.A_I_Avg, name = \"A_I_Avg\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x = data.index, \n",
    "                         y=data.A_I_Avg.diff(), name = \"Difference\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëáüèº Filter the data into two modes: ramping & steady.\n",
    "\n",
    "Hint - peek above on how we filtered fan speed based on value bins!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a performance map\n",
    "Using the coefficient of performance and the current, build a performance map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, \n",
    "                 x = \"A_I_Avg\", \n",
    "                 y=\"cop\", \n",
    "                 color = \"FanSpeed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ What next? How can you start using Python for your data analysis? Here are some ideas for getting started.\n",
    "\n",
    "<br>\n",
    "\n",
    "‚¨áÔ∏è __DOWNLOAD PYTHON__: Anaconda is a distribution of the Python and R programming languages for scientific computing, that aims to simplify package management and deployment. Anaconda installation [here](https://www.anaconda.com/products/individual). \n",
    "<br>\n",
    "\n",
    "üêç __PYTHON INTRODUCTION__: If you want an exhaustive introduction to Python, make sure to check out the official [documentation](https://docs.python.org/3/) \n",
    "<br>\n",
    "\n",
    "ü§ì __PYTHON FOR DATA ANALYSIS__: If you want additional information on how Python can be used for data analysis, check out this [ebook](https://bedford-computing.co.uk/learning/wp-content/uploads/2015/10/Python-for-Data-Analysis.pdf)\n",
    "<br>\n",
    "\n",
    "üß† __GET INVOLVED__: You can always reach out to Alexandra (alexandra@unifai.dev) with any questions! If you like learning about data science, you can also sign up to [this meetup group](https://www.meetup.com/Women-in-Data-Science-Oslo) to get invitations to more hands on workshops! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
